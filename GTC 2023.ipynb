{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e155f6c-ada2-4a48-a967-84aa1f0ef011",
   "metadata": {},
   "source": [
    "# cuSpatial API demo\n",
    "GTC April 2023 Michael Wang and Thomson Comer\n",
    "\n",
    "\n",
    "The following notebook demonstrates the use of cuSpatial to perform analytics using large datasets.\n",
    "\n",
    "The structure of the notebook is as follows:\n",
    "1. Imports\n",
    "2. Read datasets: National Address Database (NAD), NYC Taxi Boroughs Polygons, 2015 NYC Taxi pickup/dropoff information with lon/lat. Also convert epsg:2263 (NYC Long Island) to WSG.\n",
    "3. Convert separate lon/lat columns in DataFrames into cuspatial.GeoSeries\n",
    "4. Count the number of pickups and dropoffs per zone\n",
    "5. Compute street names for each pickup and dropoff\n",
    "6. Calculate the number of addresses per zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77a16fd2-9ae1-4725-bf0a-97b9ecd9dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cuspatial\n",
    "import geopandas\n",
    "import cupy as cp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393edadb-fc55-4bb6-a16c-b8ba40817324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I/O (18GB NAD, 265 borough polygons, 7m taxi pickups and 16m taxi dropoffs.\n",
    "NAD_Street = cudf.read_csv('NAD_r11.txt', usecols=[\n",
    "    'State',\n",
    "    'StN_PreDir',\n",
    "    'StreetName',\n",
    "    'StN_PosTyp',\n",
    "    'Add_Number'\n",
    "])\n",
    "NAD = cudf.read_csv('NAD_r11.txt', usecols=[\n",
    "    'State',\n",
    "    'Longitude',\n",
    "    'Latitude',\n",
    "])\n",
    "NAD = NAD[NAD['State'] == 'NY']\n",
    "NAD_Street = NAD_Street[NAD_Street['State'] == 'NY']\n",
    "# Read taxi_zones.zip shapefile with GeoPandas, then convert to epsg:4326 for lon/lat\n",
    "host_zones = geopandas.read_file('taxi_zones.zip')\n",
    "host_lonlat = host_zones.to_crs(epsg=4326)\n",
    "zones = cuspatial.from_geopandas(host_lonlat)\n",
    "taxi2015 = cudf.read_csv('taxi2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b11048d-a75f-4fc6-91d3-66bf4c658d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to convert dataframes into GeoSeries\n",
    "\n",
    "def make_geoseries_from_lon_lat(lon, lat):\n",
    "    # Scatter the two columns into one column\n",
    "    assert len(lon) == len(lat)\n",
    "    xy = cudf.Series(cp.zeros(len(lon) * 2))\n",
    "    xy[::2] = lon\n",
    "    xy[1::2] = lat\n",
    "\n",
    "    return cuspatial.GeoSeries(cuspatial.core._column.geocolumn.GeoColumn._from_points_xy(xy._column))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da697bb0-d405-4c0e-8030-4b2b099ab863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert DataFrames to GeoSeries\n",
    "\n",
    "pickups = make_geoseries_from_lon_lat(\n",
    "    taxi2015['pickup_longitude'],\n",
    "    taxi2015['pickup_latitude']\n",
    ")\n",
    "addresses = make_geoseries_from_lon_lat(\n",
    "    NAD['Longitude'],\n",
    "    NAD['Latitude']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31f08df3-3c42-4934-adbc-9e9c5d5484c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cuSpatial failure at: /home/tcomer/mnt/NVIDIA/rapids-docker/cuspatial/cpp/src/spatial/point_in_polygon.cu:140: Number of polygons cannot exceed 31",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Count the number of dropoffs and pickups per zone, one at a time.\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m pickup_counts \u001b[38;5;241m=\u001b[39m \u001b[43mzones\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgeometry\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains_properly\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpickups\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m      4\u001b[0m zones[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpickup_counts\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pickup_counts\n",
      "File \u001b[0;32m~/cuspatial/python/cuspatial/cuspatial/core/geoseries.py:876\u001b[0m, in \u001b[0;36mGeoSeries.contains_properly\u001b[0;34m(self, other, align)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcontains_properly\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, align\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    797\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a `Series` of `dtype('bool')` with value `True` for each\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;124;03m    aligned geometry that contains _other_.\u001b[39;00m\n\u001b[1;32m    799\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;124;03m        within the corresponding polygon in the input.\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mContainsProperlyBinpred\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malign\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cuspatial/python/cuspatial/cuspatial/core/binpreds/binpreds.py:125\u001b[0m, in \u001b[0;36mBinaryPredicate.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    122\u001b[0m (lhs, rhs, indices) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlhs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrhs)\n\u001b[1;32m    124\u001b[0m \u001b[38;5;66;03m# Binpred call\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m point_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrhs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# Postprocess: Apply discrete math rules to identify relationships.\u001b[39;00m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(indices, point_result)\n",
      "File \u001b[0;32m~/cuspatial/python/cuspatial/cuspatial/core/binpreds/binpreds.py:173\u001b[0m, in \u001b[0;36mContainsProperlyBinpred._op\u001b[0;34m(self, lhs, points)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    169\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`.contains` can only be called with polygon series.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    170\u001b[0m     )\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# call pip on the three subtypes on the right:\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m point_result \u001b[38;5;241m=\u001b[39m \u001b[43mcontains_properly\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpoints\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlhs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolygons\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpart_offset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlhs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolygons\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mring_offset\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlhs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolygons\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlhs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolygons\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m point_result\n",
      "File \u001b[0;32m~/cuspatial/python/cuspatial/cuspatial/core/binpreds/contains.py:79\u001b[0m, in \u001b[0;36mcontains_properly\u001b[0;34m(test_points_x, test_points_y, poly_offsets, poly_ring_offsets, poly_points_x, poly_points_y)\u001b[0m\n\u001b[1;32m     70\u001b[0m     pip_result \u001b[38;5;241m=\u001b[39m cpp_pairwise_point_in_polygon(\n\u001b[1;32m     71\u001b[0m         test_points_x,\n\u001b[1;32m     72\u001b[0m         test_points_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m         poly_points_y,\n\u001b[1;32m     77\u001b[0m     )\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     pip_result \u001b[38;5;241m=\u001b[39m \u001b[43mcpp_point_in_polygon\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_points_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_points_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoly_offsets_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoly_ring_offsets_column\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoly_points_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     85\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpoly_points_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     88\u001b[0m result \u001b[38;5;241m=\u001b[39m Series(pip_result, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbool\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32mpoint_in_polygon.pyx:32\u001b[0m, in \u001b[0;36mcuspatial._lib.point_in_polygon.point_in_polygon\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuSpatial failure at: /home/tcomer/mnt/NVIDIA/rapids-docker/cuspatial/cpp/src/spatial/point_in_polygon.cu:140: Number of polygons cannot exceed 31"
     ]
    }
   ],
   "source": [
    "# Count the number of dropoffs and pickups per zone, one at a time.\n",
    "\n",
    "pickup_counts = zones['geometry'].contains_properly(pickups, align=False).sum()\n",
    "zones['pickup_counts'] = pickup_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8add5-c303-4c84-8ac8-d94389ae8422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadtree(polygons, points):\n",
    "    poly_points_x = polygons.polygons.x\n",
    "    poly_points_y = polygons.polygons.y\n",
    "    poly_offsets = polygons.polygons.part_offset\n",
    "    poly_ring_offsets = polygons.polygons.ring_offset\n",
    "    test_points_x = points.points.x\n",
    "    test_points_y = points.points.y\n",
    "    scale = 50\n",
    "    max_depth = 7\n",
    "    min_size = 125\n",
    "    x_max = poly_points_x.max()\n",
    "    x_min = poly_points_x.min()\n",
    "    y_max = poly_points_y.max()\n",
    "    y_min = poly_points_y.min()\n",
    "    point_indices, quadtree = cuspatial.quadtree_on_points(\n",
    "        test_points_x,\n",
    "        test_points_y,\n",
    "        x_min,\n",
    "        x_max,\n",
    "        y_min,\n",
    "        y_max,\n",
    "        scale,\n",
    "        max_depth,\n",
    "        min_size,\n",
    "    )\n",
    "    poly_bboxes = cuspatial.polygon_bounding_boxes(\n",
    "        poly_offsets, poly_ring_offsets, poly_points_x, poly_points_y\n",
    "    )\n",
    "    intersections = cuspatial.join_quadtree_and_bounding_boxes(\n",
    "        quadtree, poly_bboxes, x_min, x_max, y_min, y_max, scale, max_depth\n",
    "    )\n",
    "    polygons_and_points = cuspatial.quadtree_point_in_polygon(\n",
    "        intersections,\n",
    "        quadtree,\n",
    "        point_indices,\n",
    "        test_points_x,\n",
    "        test_points_y,\n",
    "        poly_offsets,\n",
    "        poly_ring_offsets,\n",
    "        poly_points_x,\n",
    "        poly_points_y,\n",
    "    )\n",
    "    polygons_and_points['point_index'] = point_indices.iloc[\n",
    "        polygons_and_points['point_index']\n",
    "    ].reset_index(drop=True)\n",
    "    return polygons_and_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a423bb-7058-42bc-b8d9-d6af1cd16edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses_pip = quadtree(zones['geometry'], addresses)\n",
    "addresses_pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb654b04-86d8-4a5f-9b61-78894457d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickups_pip = quadtree(zones['geometry'].iloc[0:120], pickups)\n",
    "pickups_pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a002c70e-0936-4615-b3c1-f3eefbea7655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a mapping from parts to polygons\n",
    "\n",
    "def pip_result_to_id_map(polygons, pip_result):\n",
    "    offsets = cp.array(polygons.polygons.geometry_offset)\n",
    "    polygon_lengths = offsets[1:] - offsets[:-1]\n",
    "    parts = polygons.polygons.part_offset\n",
    "    polygon_map = cp.arange(len(polygon_lengths)).repeat(polygon_lengths.tolist())\n",
    "    idx_df = cudf.DataFrame({\n",
    "        'OBJECTID': polygon_map,\n",
    "        'polygon_index': cp.arange(len(parts)-1)\n",
    "    })\n",
    "    return pip_result.merge(idx_df, on=\"polygon_index\").drop('polygon_index', axis=1)\n",
    "borough_addresses = pip_result_to_id_map(zones['geometry'], addresses_pip)\n",
    "borough_pickups = pip_result_to_id_map(zones['geometry'], pickups_pip)\n",
    "borough_addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ea23a-dff4-4ae4-b39b-982df2e597db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's compute the practical limit for actual boroughs.\n",
    "pickup_counts = borough_pickups.groupby('OBJECTID').count()\n",
    "address_counts = borough_addresses.groupby('OBJECTID').count()\n",
    "pickup_counts = pickup_counts.fillna(0)\n",
    "address_counts = address_counts.fillna(0)\n",
    "comparison_size = pickup_counts.sort_index()['point_index'] * address_counts.sort_index()['point_index']\n",
    "HARDEST_BOROUGH = comparison_size[comparison_size == comparison_size.max()].index[0]\n",
    "BOROUGH_ID = HARDEST_BOROUGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399d5843-874e-442a-8cfc-9b1f7d94a395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's make two GeoSeries: For each borough, create a GeoSeries with all address Points\n",
    "# repeated the number of times there are pickups in that borough, and another GeoSeries with\n",
    "# the opposite: all pickups Points repeated the number of times there are addresses in that\n",
    "# borough.\n",
    "\n",
    "# addresses\n",
    "borough_address_point_ids = borough_addresses['point_index'][borough_addresses['OBJECTID'] == BOROUGH_ID]\n",
    "pickups_count = len(borough_pickups[borough_pickups['OBJECTID'] == BOROUGH_ID])\n",
    "print(borough_address_point_ids)\n",
    "print(pickups_count)\n",
    "addresses_tiled = NAD.iloc[\n",
    "    borough_address_point_ids\n",
    "].tile(pickups_count)\n",
    "\n",
    "# pickups\n",
    "addresses_ids = borough_address_point_ids.tile(pickups_count).reset_index(drop=True)\n",
    "borough_pickup_point_ids = borough_pickups['point_index'][borough_pickups['OBJECTID'] == BOROUGH_ID]\n",
    "addresses_count = len(borough_addresses[borough_addresses['OBJECTID'] == BOROUGH_ID])\n",
    "pickups_tiled = taxi2015[[\n",
    "    'pickup_longitude',\n",
    "    'pickup_latitude'\n",
    "]].iloc[\n",
    "    borough_pickup_point_ids\n",
    "].tile(addresses_count)\n",
    "\n",
    "# map of pickup ids so we can reconstruct which are the closets\n",
    "pickups_ids = borough_pickup_point_ids.tile(addresses_count).reset_index(drop=True)\n",
    "\n",
    "pickup_points = make_geoseries_from_lon_lat(\n",
    "    pickups_tiled['pickup_longitude'],\n",
    "    pickups_tiled['pickup_latitude']\n",
    ")\n",
    "address_points = make_geoseries_from_lon_lat(\n",
    "    addresses_tiled['Longitude'],\n",
    "    addresses_tiled['Latitude']\n",
    ")\n",
    "addresses_tiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e5f68c-ad66-428d-8cd6-6e1268d5e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of addresses and their indices that are closest to a pickup point\n",
    "\n",
    "distances = cuspatial.pairwise_point_distance(pickup_points, address_points)\n",
    "\n",
    "pickups_indices = cp.arange((borough_pickups['OBJECTID'] == BOROUGH_ID).sum())\n",
    "addresses_indices = cudf.Series(cp.arange((borough_addresses['OBJECTID'] == BOROUGH_ID).sum()))\n",
    "pickups_index_map = pickups_indices.repeat((borough_addresses['OBJECTID'] == BOROUGH_ID).sum())\n",
    "address_index_map = addresses_indices.tile((borough_pickups['OBJECTID'] == BOROUGH_ID).sum())\n",
    "gb_df = cudf.DataFrame({\n",
    "    'address': addresses_tiled.index,\n",
    "    'pickup': pickups_tiled.index,\n",
    "    'distances': distances\n",
    "}) \n",
    "address_indices_of_nearest = gb_df[['address', 'distances']].groupby('address').idxmin()\n",
    "pickup_indices_of_nearest = gb_df[['pickup', 'distances']].groupby('pickup').idxmin()\n",
    "address_pickup_minimum_correspondence = gb_df.iloc[pickup_indices_of_nearest['distances']]\n",
    "address_pickup_minimum_correspondence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abd09dd-8207-4550-88bb-0ccbd32c4055",
   "metadata": {},
   "outputs": [],
   "source": [
    "nearest_pickups = taxi2015.iloc[address_pickup_minimum_correspondence['pickup']]\n",
    "nearest_addresses = NAD_Street.loc[address_pickup_minimum_correspondence['address']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d52460-d36a-4cbc-bf5a-f1be82b89eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate address fields\n",
    "\n",
    "def build_address_string(NAD_Street):\n",
    "    blanks = cudf.Series([' '] * len(NAD_Street))\n",
    "    blanks.index = NAD_Street.index\n",
    "    NAD_Street['StN_PreDir'] = NAD_Street['StN_PreDir'].fillna('')\n",
    "    NAD_Street['StN_PosTyp'] = NAD_Street['StN_PosTyp'].fillna('')\n",
    "    street_names = NAD_Street['Add_Number'].astype('str').str.cat(\n",
    "        blanks\n",
    "    ).str.cat(\n",
    "        NAD_Street['StN_PreDir']\n",
    "    ).str.cat(\n",
    "        blanks\n",
    "    ).str.cat(\n",
    "        NAD_Street['StreetName']\n",
    "    ).str.cat(\n",
    "        blanks\n",
    "    ).str.cat(\n",
    "        NAD_Street['StN_PosTyp']\n",
    "    )\n",
    "    return street_names.str.replace('  ', ' ')\n",
    "\n",
    "build_address_string(nearest_addresses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070bc274-1642-49d5-903b-ee4baabe8a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_index = nearest_pickups.reset_index()\n",
    "no_index['addresses'] = build_address_string(nearest_addresses).reset_index(drop=True)\n",
    "taxi_pickups_with_address = no_index.set_index(no_index['index'])\n",
    "taxi_pickups_with_address.iloc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84aed190-f953-49a9-8706-e3ca8ede8e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of addresses per borough\n",
    "\n",
    "address_counts = borough_addresses.groupby('OBJECTID').count()\n",
    "count_df = cudf.DataFrame({\n",
    "    'OBJECTID': address_counts.index,\n",
    "    \"Address Count\": address_counts.polygon_index\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafda2f6-0270-4ba5-a9fd-c10fdfc8e6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the address counts back to the zones dataframe\n",
    "\n",
    "# Cudf doesn't know how to print `geometry` columns, so put it back into cuspatial\n",
    "merged_zones = cuspatial.GeoDataFrame(zones.merge(count_df))\n",
    "merged_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebfb41d-3e89-4175-8e94-933f98c57d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have the street names in NAD above, let's add the street name to each pickup\n",
    "\n",
    "borough_addresses\n",
    "print(NAD.head())\n",
    "print(taxi2015.head())\n",
    "print(pickups.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd188f4a-ebed-4541-91d8-c67f1f62307a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
