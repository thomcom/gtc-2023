{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77a16fd2-9ae1-4725-bf0a-97b9ecd9dc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf\n",
    "import cuspatial\n",
    "import geopandas\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "393edadb-fc55-4bb6-a16c-b8ba40817324",
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "Error creating dataset. Could not read schema from '/home/tcomer/mnt/NVIDIA/rapids-docker/cuspatial/notebooks/thomcom_notebooks/GTC 2023/rapids-carto-talk/modules/datasets/data/polys.arrow': Could not open Parquet input source '/home/tcomer/mnt/NVIDIA/rapids-docker/cuspatial/notebooks/thomcom_notebooks/GTC 2023/rapids-carto-talk/modules/datasets/data/polys.arrow': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.. Is this a 'parquet' file?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m zones \u001b[38;5;241m=\u001b[39m \u001b[43mcudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrapids-carto-talk/modules/datasets/data/polys.arrow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m taxi2015 \u001b[38;5;241m=\u001b[39m cudf\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtaxi2015.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/compose/etc/conda/cuda_11.6/envs/notebooks/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cudf/python/cudf/cudf/io/parquet.py:480\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(filepath_or_buffer, engine, columns, storage_options, filters, row_groups, strings_to_categorical, use_pandas_metadata, use_python_file_object, categorical_partitions, open_file_options, bytes_per_thread, *args, **kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m partition_categories \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fs \u001b[38;5;129;01mand\u001b[39;00m paths:\n\u001b[1;32m    475\u001b[0m     (\n\u001b[1;32m    476\u001b[0m         paths,\n\u001b[1;32m    477\u001b[0m         row_groups,\n\u001b[1;32m    478\u001b[0m         partition_keys,\n\u001b[1;32m    479\u001b[0m         partition_categories,\n\u001b[0;32m--> 480\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[43m_process_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpaths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow_groups\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow_groups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_partitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_partitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m filters \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcudf cannot apply filters to open file objects.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/compose/etc/conda/cuda_11.6/envs/notebooks/lib/python3.8/contextlib.py:75\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 75\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/cudf/python/cudf/cudf/io/parquet.py:296\u001b[0m, in \u001b[0;36m_process_dataset\u001b[0;34m(paths, fs, filters, row_groups, categorical_partitions)\u001b[0m\n\u001b[1;32m    291\u001b[0m     filters \u001b[38;5;241m=\u001b[39m pq\u001b[38;5;241m.\u001b[39mfilters_to_expression(filters)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;66;03m# Initialize ds.FilesystemDataset\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# TODO: Remove the if len(paths) workaround after following bug is fixed:\u001b[39;00m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# https://issues.apache.org/jira/browse/ARROW-16438\u001b[39;00m\n\u001b[0;32m--> 296\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpaths\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpartitioning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhive\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m file_list \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mfiles\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(file_list) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/compose/etc/conda/cuda_11.6/envs/notebooks/lib/python3.8/site-packages/pyarrow/dataset.py:752\u001b[0m, in \u001b[0;36mdataset\u001b[0;34m(source, schema, format, filesystem, partitioning, partition_base_dir, exclude_invalid_files, ignore_prefixes)\u001b[0m\n\u001b[1;32m    741\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    742\u001b[0m     schema\u001b[38;5;241m=\u001b[39mschema,\n\u001b[1;32m    743\u001b[0m     filesystem\u001b[38;5;241m=\u001b[39mfilesystem,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    748\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mignore_prefixes\n\u001b[1;32m    749\u001b[0m )\n\u001b[1;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_path_like(source):\n\u001b[0;32m--> 752\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_filesystem_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(source, (\u001b[38;5;28mtuple\u001b[39m, \u001b[38;5;28mlist\u001b[39m)):\n\u001b[1;32m    754\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(_is_path_like(elem) \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m source):\n",
      "File \u001b[0;32m~/compose/etc/conda/cuda_11.6/envs/notebooks/lib/python3.8/site-packages/pyarrow/dataset.py:454\u001b[0m, in \u001b[0;36m_filesystem_dataset\u001b[0;34m(source, schema, filesystem, partitioning, format, partition_base_dir, exclude_invalid_files, selector_ignore_prefixes)\u001b[0m\n\u001b[1;32m    446\u001b[0m options \u001b[38;5;241m=\u001b[39m FileSystemFactoryOptions(\n\u001b[1;32m    447\u001b[0m     partitioning\u001b[38;5;241m=\u001b[39mpartitioning,\n\u001b[1;32m    448\u001b[0m     partition_base_dir\u001b[38;5;241m=\u001b[39mpartition_base_dir,\n\u001b[1;32m    449\u001b[0m     exclude_invalid_files\u001b[38;5;241m=\u001b[39mexclude_invalid_files,\n\u001b[1;32m    450\u001b[0m     selector_ignore_prefixes\u001b[38;5;241m=\u001b[39mselector_ignore_prefixes\n\u001b[1;32m    451\u001b[0m )\n\u001b[1;32m    452\u001b[0m factory \u001b[38;5;241m=\u001b[39m FileSystemDatasetFactory(fs, paths_or_selector, \u001b[38;5;28mformat\u001b[39m, options)\n\u001b[0;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfactory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfinish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mschema\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/compose/etc/conda/cuda_11.6/envs/notebooks/lib/python3.8/site-packages/pyarrow/_dataset.pyx:1940\u001b[0m, in \u001b[0;36mpyarrow._dataset.DatasetFactory.finish\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/compose/etc/conda/cuda_11.6/envs/notebooks/lib/python3.8/site-packages/pyarrow/error.pxi:144\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/compose/etc/conda/cuda_11.6/envs/notebooks/lib/python3.8/site-packages/pyarrow/error.pxi:100\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: Error creating dataset. Could not read schema from '/home/tcomer/mnt/NVIDIA/rapids-docker/cuspatial/notebooks/thomcom_notebooks/GTC 2023/rapids-carto-talk/modules/datasets/data/polys.arrow': Could not open Parquet input source '/home/tcomer/mnt/NVIDIA/rapids-docker/cuspatial/notebooks/thomcom_notebooks/GTC 2023/rapids-carto-talk/modules/datasets/data/polys.arrow': Parquet magic bytes not found in footer. Either the file is corrupted or this is not a parquet file.. Is this a 'parquet' file?"
     ]
    }
   ],
   "source": [
    "zones = .read_parquet('rapids-carto-talk/modules/datasets/data/polys.arrow'))\n",
    "taxi2015 = cudf.read_csv('taxi2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b11048d-a75f-4fc6-91d3-66bf4c658d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_list_series_from_lon_lat(lon, lat):\n",
    "    from cudf.core.column import build_list_column, arange\n",
    "    \n",
    "    assert len(lon) == len(lat)\n",
    "    xy = cudf.Series(cp.zeros(len(lon) * 2))\n",
    "    xy[::2] = lon\n",
    "    xy[1::2] = lat\n",
    "\n",
    "    elements = cudf.Series(xy)._column\n",
    "    indices = arange(0, len(elements) + 1, 2, dtype=\"int32\")\n",
    "    size = len(lon)\n",
    "    list_column = build_list_column(\n",
    "        indices=indices,\n",
    "        elements=elements,\n",
    "        size=size\n",
    "    )\n",
    "    return cudf.Series(list_column)\n",
    "    \n",
    "def make_geoseries_from_list_series(series):    \n",
    "    from cudf.core.column import build_list_column\n",
    "    from cuspatial.core._column.geometa import Feature_Enum, GeoMeta\n",
    "    from cuspatial.core._column.geocolumn import GeoColumn\n",
    "    geo_col = GeoColumn(\n",
    "        (\n",
    "            series,\n",
    "            cudf.Series(),\n",
    "            cudf.Series(),\n",
    "            cudf.Series()\n",
    "        ),\n",
    "        GeoMeta({\n",
    "            \"input_types\": cp.full(\n",
    "                len(series),\n",
    "                Feature_Enum.POINT.value,\n",
    "            ),\n",
    "            \"union_offsets\": cp.arange(len(series))\n",
    "        })\n",
    "    )\n",
    "    return cuspatial.GeoSeries(geo_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da697bb0-d405-4c0e-8030-4b2b099ab863",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickups_cudf = make_list_series_from_lon_lat(\n",
    "    taxi2015['pickup_longitude'],\n",
    "    taxi2015['pickup_latitude']\n",
    ")\n",
    "pickups = make_geoseries_from_list_series(pickups_cudf)\n",
    "dropoffs_cudf = make_list_series_from_lon_lat(\n",
    "    taxi2015['dropoff_longitude'],\n",
    "    taxi2015['dropoff_latitude']\n",
    ")\n",
    "dropoffs = make_geoseries_from_list_series(dropoffs_cudf)\n",
    "pickups = cuspatial.GeoSeries(cuspatial.core._column.geocolumn.GeoColumn._from_points_xy(taxi2015['pickup_longitude']._column))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ea65853c-2381-4060-a3f2-aabc148a82f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "498 ms ± 14.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit zones[\"geometry\"].iloc[0:1].contains_properly(dropoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e928826-4148-49cb-87ea-6b8bfee47618",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_pickups = pickups.to_geopandas()\n",
    "host_dropoffs = dropoffs.to_geopandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "cfad01f2-d99f-4316-9d6e-2529585431f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "host_polys = zones[\"geometry\"].to_geopandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "eb0c5b16-81cf-47cf-bb06-88120ddd04ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      POLYGON ((933100.918 192536.086, 933091.011 19...\n",
       "1      MULTIPOLYGON (((1033269.244 172126.008, 103343...\n",
       "2      POLYGON ((1026308.770 256767.698, 1026495.593 ...\n",
       "3      POLYGON ((992073.467 203714.076, 992068.667 20...\n",
       "4      POLYGON ((935843.310 144283.336, 936046.565 14...\n",
       "                             ...                        \n",
       "258    POLYGON ((1025414.782 270986.139, 1025138.624 ...\n",
       "259    POLYGON ((1011466.966 216463.005, 1011545.889 ...\n",
       "260    POLYGON ((980555.204 196138.486, 980570.792 19...\n",
       "261    MULTIPOLYGON (((999804.795 224498.527, 999824....\n",
       "262    POLYGON ((997493.323 220912.386, 997355.264 22...\n",
       "Name: geometry, Length: 263, dtype: geometry"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "host_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd9ba6b1-84f6-41a3-b1fd-6c9b44775c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tcomer/mnt/NVIDIA/rapids-docker/compose/etc/conda/cuda_11.6/envs/notebooks/lib/python3.8/site-packages/geopandas/base.py:31: UserWarning: The indices of the two GeoSeries are different.\n",
      "  warn(\"The indices of the two GeoSeries are different.\")\n"
     ]
    }
   ],
   "source": [
    "gpu_pip = zones[\"geometry\"].iloc[0:1].contains_properly(dropoffs)\n",
    "host_pip = zones[\"geometry\"].to_geopandas().iloc[0:1].contains(host_dropoffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "31f08df3-3c42-4934-adbc-9e9c5d5484c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(gpu_pip.to_pandas() == host_pip).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c8add5-c303-4c84-8ac8-d94389ae8422",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
